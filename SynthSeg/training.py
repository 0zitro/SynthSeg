# python imports
import os
import logging
import numpy as np
from keras.models import Model
from keras.optimizers import Adam
from argparse import ArgumentParser
from keras.callbacks import TensorBoard
from keras.callbacks import ModelCheckpoint

# project imports
from . import metrics_model
from .brain_generator import BrainGenerator

# third-party imports
from ext.lab2im import utils
from ext.neuron import models as nrn_models


def training(labels_dir,
             model_dir,
             path_generation_labels=None,
             path_segmentation_labels=None,
             batch_size=1,
             n_channels=1,
             target_res=None,
             output_shape=None,
             flipping=True,
             prior_distributions='uniform',
             prior_means=None,
             prior_stds=None,
             use_specific_stats_for_channel=False,
             path_generation_classes=None,
             scaling_bounds=0.07,
             rotation_bounds=10,
             shearing_bounds=0.01,
             nonlin_shape_factor=0.04,
             nonlin_std_dev=3,
             blur_background=True,
             data_res=None,
             thickness=None,
             downsample=False,
             blur_range=1.15,
             crop_channel_2=None,
             bias_shape_factor=0.025,
             bias_field_std_dev=0.3,
             n_levels=5,
             nb_conv_per_level=2,
             conv_size=3,
             unet_feat_count=24,
             feat_multiplier=2,
             dropout=0,
             no_batch_norm=False,
             lr=1e-4,
             lr_decay=0,
             wl2_epochs=5,
             dice_epochs=100,
             steps_per_epoch=1000,
             background_weight=1e-4,
             include_background=False,
             loss_cropping=None,
             load_model_file=None,
             initial_epoch_wl2=0,
             initial_epoch_dice=0,
             save_generation_labels=None):
    """
    This function trains a Unet to segment MRI images with synthetic scans generated by sampling a GMM conditioned on
    label maps.
    :param labels_dir: path of folder with all input label maps
    :param model_dir: path of a directory where the models will be saved during training.
    :param path_generation_labels: path to a numpy array of all possible label values in the input label maps.
    Should be organised as follows: background label first, then non-sided labels (e.g. CSF, brainstem, etc.), then
    all the structures of the same hemisphere (can be left or right), and finally all the corresponding
    contralateral structures (in the same order).
    Default is None, where the label values are directly gotten from the provided label maps.
    :param path_segmentation_labels: (optional) path to a numpy array of all the label values to keep in the output
    label maps, in no particular order. Labels that are in generation_labels but not in output_labels are reset to zero.
    :param batch_size: (optional) numbers of images to generate per mini-batch. Default is 1.
    :param n_channels: (optional) number of channels to be synthetised. Default is 1.
    :param target_res: (optional) target resolution of the generated images and corresponding label maps.
    If None, the outputs will have the same resolution as the input label maps.
    Can be a number (isotropic resolution), or the path to a 1d numpy array.
    :param output_shape: (optional) desired shape of the output images.
    If the atlas and target resolutions are the same, the output will be cropped to output_shape, and if the two
    resolutions are different, the output will be resized with trilinear interpolation to output_shape.
    Can be an integer (same size in all dimensions), or the path to a 1d numpy array.
    :param flipping: (optional) whether to introduce right/left random flipping. Default is True.
    :param prior_distributions: (optional) type of distribution from which we sample the GMM parameters.
    Can either be 'uniform', or 'normal'. Default is 'uniform'.
    :param prior_means: (optional) hyperparameters controlling the prior distributions of the GMM means. Because
    these prior distributions are uniform or normal, they require by 2 hyperparameters. Can be:
    1) an array of shape (2, n_labels). The mean of the Gaussian distribution associated to label k is sampled at
    each mini_batch from U(prior_means[0,k], prior_means[1,k]) if prior_distributions is uniform, and from
    N(prior_means[0,k], prior_means[1,k]) if prior_distributions is normal.
    2) an array of shape (2*n_mod, n_labels), where each block of two rows is associated to hyperparameters derived
    from different modalities. In this case, if use_specific_stats_for_channel is False, we first randomly select a
    modality from the n_mod possibilities, and we sample the GMM means like in 2).
    If use_specific_stats_for_channel is True, each block of two rows correspond to a different channel
    (n_mod=n_channels), thus we select the corresponding block to each channel rather than randomly drawing it.
    Default is None, which corresponds all GMM means sampled from unform distribution U(25, 225).
    :param prior_stds: (optional) same as prior_means but for the standard deviations of the GMM.
    Default is None, which corresponds to U(5, 25).
    :param use_specific_stats_for_channel: (optional) whether the i-th block of two rows in the prior arrays must be
    only used to generate the i-th channel. If True, n_mod should be equal to n_channels. Default is False.
    :param path_generation_classes: (optional) Indices regrouping generation labels into classes when sampling the GMM.
    Intensities of corresponding to regouped labels will thus be sampled from the same distribution. Must have the
    same length as generation_labels. Must be a path to a 1d numpy array. Default is all labels have different classes.
    :param scaling_bounds: (optional) if apply_linear_trans is True, the scaling factor for each dimension is
    sampled from a uniform distribution of predefined bounds. Can either be:
    1) a number, in which case the scaling factor is independently sampled from the uniform distribution of bounds
    1-scaling_bounds, 1+scaling_bounds) for each dimension.
    2) the path to a numpy array of shape (2, n_dims), in which case the scaling factor is sampled from the uniform
    distribution of bounds (scaling_bounds[0, i], scaling_bounds[1, i]) for the i-th dimension.
    If None (default), scaling_range = 0.15
    :param rotation_bounds: (optional) same as scaling bounds but for the rotation angle, except that for case 1 the
    bounds are centred on 0 rather than 1, i.e. (0+rotation_bounds[i], 0-rotation_bounds[i]).
    If None (default), rotation_bounds = 15.
    :param shearing_bounds: (optional) same as scaling bounds. If None (default), shearing_bounds = 0.01.
    :param nonlin_shape_factor: (optional) Ratio between the size of the input label maps and the size of the sampled
    tensor for synthesising the elastic deformation field.
    :param nonlin_std_dev: (optional) Standard deviation of the normal distribution from which we sample the first
    tensor for synthesising the deformation field.
    :param blur_background: (optional) If True, the background is blurred with the other labels, and can be reset to
    zero with a probability of 0.2. If False, the background is not blurred (we apply an edge blurring correction),
    and can be replaced by a low-intensity background with a probability of 0.5.
    :param data_res: (optional) If provided, the generated images are blurred to mimick data that would be: acquired
    at the given lower resolution, and then resampled at target_resolution. Default is None, where images are
    slightly isotropically blurred to introduce some spatial correlation between voxels.
    Can be an number (isotropic resolution), or the path to a 1d numpy array.
    :param thickness: optional) if data_res is provided, we can further specify the slice thickness of the low
    resolution images to mimick. Can be a number (isotropic thickness), or the path to a 1d numpy array.
    :param downsample: (optional) whether to actually downsample the volume image to data_res. Default is False.
    :param blur_range: (optional) Randomise the standard deviation of the blurring kernels, (whether data_res is given
    or not). At each mini_batch, the standard deviation of the blurring kernels are multiplied by a coefficient sampled
    from a uniform distribution with bounds [1/blur_range, blur_range]. If None, no randomisation. Default is 1.15.
    :param crop_channel_2: (optional) stats for cropping second channel along the anterior-posterior axis.
    Should be the path to a 1d numpy array of length 4, with bounds of uniform distribution for cropping the front and
    back of the image (in percentage). None is no croppping.
    :param bias_shape_factor: (optional) Ratio between the size of the input label maps and the size of the sampled
    tensor for synthesising the bias field.
    :param bias_field_std_dev: (optional) Standard deviation of the normal distribution from which we sample the first
    tensor for synthesising the bias field.
    :param n_levels: (optional) number of level for the Unet
    :param nb_conv_per_level: (optional) number of convolutional layers per level. Default is 2.
    :param conv_size: (optional) size of the convolution kernels. Default is 2.
    :param unet_feat_count: (optional) number of feature for the first layr of the Unet. Default is 24.
    :param feat_multiplier: (optional) multiply the number of feature by this nummber at each new level. Default is 1.
    :param dropout: (optional) probability of drpout for the Unet. Deafult is 0, where no dropout is applied.
    :param no_batch_norm: (optional) wheter to remove batch normalisation. Default is False, where BN is applied.
    :param lr: (optional) learning rate for the training. Default is 1e-4
    :param lr_decay: (optional) learing rate decay. Default is 0, where no decay is applied.
    :param wl2_epochs: (optional) number of epohs for which the network (except the soft-max layer) is trained with L2
    norm loss function. Default is 5.
    :param dice_epochs: (optional) number of epochs with the soft Dice loss function. default is 100.
    :param steps_per_epoch: (optional) number of steps per epoch. Default is 1000. Since no online validation is
    possible, this is equivalent to the frequency at which the models are saved.
    :param background_weight: (optional) weight of the background when computing loss. Default is 1e-4.
    :param include_background: (optional) whether to include Dice of background when evaluating the loss function.
    :param loss_cropping: (optional) margin by which to crop the posteriors when evaluating the loss function.
    Can be an int, or the path to a 1d numpy array.
    :param load_model_file: (optional) path of an already saved model to load before starting the training.
    :param initial_epoch_wl2: (optional) initial epoch for wl2 training. Useful for resuming training.
    :param initial_epoch_dice: (optional) initial epoch for dice training. Useful for resuming training.
    :param save_generation_labels: (optional) path of anumpy array where computed list of labels will be saved.
    """

    # check epochs
    assert (wl2_epochs > 0) | (dice_epochs > 0), \
        'either wl2_epochs or dice_epochs must be positive, had {0} and {1}'.format(wl2_epochs, dice_epochs)

    generation_label_list, generation_neutral_labels = utils.get_list_labels(label_list=path_generation_labels,
                                                                             labels_dir=labels_dir,
                                                                             save_label_list=save_generation_labels,
                                                                             FS_sort=True)
    if path_segmentation_labels is not None:
        segmentation_label_list, _ = utils.get_list_labels(label_list=path_segmentation_labels, FS_sort=True)
    else:
        segmentation_label_list = generation_label_list

    # number of labels (including background)
    n_segmentation_labels = np.size(segmentation_label_list)

    # prepare model folder
    if not os.path.isdir(model_dir):
        os.mkdir(model_dir)

    # prepare log folder
    log_dir = os.path.join(model_dir, 'logs')
    if not os.path.isdir(log_dir):
        os.mkdir(log_dir)

    # compute padding_margin
    padding_margin = utils.get_padding_margin(output_shape, loss_cropping)

    # instantiate BrainGenerator object
    brain_generator = BrainGenerator(labels_dir=labels_dir,
                                     generation_labels=generation_label_list,
                                     output_labels=segmentation_label_list,
                                     n_neutral_labels=generation_neutral_labels,
                                     batch_size=batch_size,
                                     n_channels=n_channels,
                                     target_res=target_res,
                                     output_shape=output_shape,
                                     output_div_by_n=2**n_levels,
                                     padding_margin=padding_margin,
                                     flipping=flipping,
                                     prior_distributions=prior_distributions,
                                     prior_means=prior_means,
                                     prior_stds=prior_stds,
                                     use_specific_stats_for_channel=use_specific_stats_for_channel,
                                     generation_classes=path_generation_classes,
                                     scaling_bounds=scaling_bounds,
                                     rotation_bounds=rotation_bounds,
                                     shearing_bounds=shearing_bounds,
                                     nonlin_shape_factor=nonlin_shape_factor,
                                     nonlin_std_dev=nonlin_std_dev,
                                     blur_background=blur_background,
                                     data_res=data_res,
                                     thickness=thickness,
                                     downsample=downsample,
                                     blur_range=blur_range,
                                     crop_channel_2=crop_channel_2,
                                     bias_shape_factor=bias_shape_factor,
                                     bias_field_std_dev=bias_field_std_dev)

    # transformation model
    labels_to_image_model = brain_generator.labels_to_image_model
    unet_input_shape = brain_generator.model_output_shape

    # prepare the segmentation model
    if no_batch_norm:
        batch_norm_dim = None
    else:
        batch_norm_dim = -1
    unet_model = nrn_models.unet(nb_features=unet_feat_count,
                                 input_shape=unet_input_shape,
                                 nb_levels=n_levels,
                                 conv_size=conv_size,
                                 nb_labels=n_segmentation_labels,
                                 feat_mult=feat_multiplier,
                                 dilation_rate_mult=1,
                                 nb_conv_per_level=nb_conv_per_level,
                                 conv_dropout=dropout,
                                 batch_norm=batch_norm_dim,
                                 input_model=labels_to_image_model)

    # input generator
    train_example_gen = brain_generator.model_inputs_generator
    training_generator = utils.build_training_generator(train_example_gen, batch_size)

    # pre-training with weighted L2, input is fit to the softmax rather than the probabilities
    if wl2_epochs > 0:
        wl2_model = Model(unet_model.inputs, [unet_model.get_layer('unet_likelihood').output])
        wl2_model = metrics_model.metrics_model(input_shape=unet_input_shape[:-1] + [n_segmentation_labels],
                                                segmentation_label_list=segmentation_label_list,
                                                input_model=wl2_model,
                                                loss_cropping=loss_cropping,
                                                metrics='weighted_l2',
                                                weight_background=background_weight,
                                                name='metrics_model')
        if load_model_file is not None:
            print('loading', load_model_file)
            wl2_model.load_weights(load_model_file)
        train_model(wl2_model, training_generator, lr, lr_decay, wl2_epochs, steps_per_epoch, model_dir, log_dir,
                    'wl2', initial_epoch_wl2)

    # fine-tuning with dice metric
    if dice_epochs > 0:
        dice_model = metrics_model.metrics_model(input_shape=unet_input_shape[:-1] + [n_segmentation_labels],
                                                 segmentation_label_list=segmentation_label_list,
                                                 input_model=unet_model,
                                                 loss_cropping=loss_cropping,
                                                 include_background=include_background,
                                                 name='metrics_model')
        if wl2_epochs > 0:
            last_wl2_model_name = os.path.join(model_dir, 'wl2_%03d.h5' % wl2_epochs)
            dice_model.load_weights(last_wl2_model_name, by_name=True)
        elif load_model_file is not None:
            print('loading', load_model_file)
            dice_model.load_weights(load_model_file)
        train_model(dice_model, training_generator, lr, lr_decay, dice_epochs, steps_per_epoch, model_dir, log_dir,
                    'dice', initial_epoch_dice)


def train_model(model,
                generator,
                lr,
                lr_decay,
                n_epochs,
                n_steps,
                model_dir,
                log_dir,
                metric_type,
                initial_epoch=0):

    # prepare callbacks
    save_file_name = os.path.join(model_dir, '%s_{epoch:03d}.h5' % metric_type)
    temp_callbacks = ModelCheckpoint(save_file_name, verbose=1)
    mg_model = model

    # TensorBoard callback
    if metric_type == 'dice':
        tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_images=False)
        callbacks = [temp_callbacks, tensorboard]
    else:
        callbacks = [temp_callbacks]

    # metric and loss
    metric = metrics_model.IdentityLoss()
    data_loss = metric.loss

    # compile
    mg_model.compile(optimizer=Adam(lr=lr, decay=lr_decay), loss=data_loss, loss_weights=[1.0])

    # fit
    mg_model.fit_generator(generator, epochs=n_epochs, steps_per_epoch=n_steps, callbacks=callbacks,
                           initial_epoch=initial_epoch)


if __name__ == "__main__":
    parser = ArgumentParser()

    # Positional arguments
    parser.add_argument("labels_dir", type=str)
    parser.add_argument("model_dir", type=str)

    # Generation parameters
    parser.add_argument("--generation_label_list", type=str, dest="path_generation_labels")
    parser.add_argument("--segmentation_label_list", type=str, dest="path_segmentation_labels")
    parser.add_argument("--batch_size", type=int, dest="batch_size")
    parser.add_argument("--channels", type=int, dest="n_channels")
    parser.add_argument("--target_res", type=float, dest="target_res")
    parser.add_argument("--output_shape", type=int, dest="output_shape")
    parser.add_argument("--no_flipping", action='store_false', dest="flipping")
    parser.add_argument("--prior_type", type=str, dest="prior_distributions")
    parser.add_argument("--prior_means", type=str, dest="prior_means")
    parser.add_argument("--prior_stds", type=str, dest="prior_stds")
    parser.add_argument("--specific_stats", action='store_true', dest="use_specific_stats_for_channel")
    parser.add_argument("--generation_classes", type=str, dest="path_generation_classes")
    parser.add_argument("--scaling", dest="scaling_bounds")
    parser.add_argument("--rotation", dest="rotation_bounds")
    parser.add_argument("--shearing", dest="shearing_bounds")
    parser.add_argument("--nonlin_shape_fact", type=float, dest="nonlin_shape_factor")
    parser.add_argument("--nonlin_std", dest="nonlin_std_dev")
    parser.add_argument("--no_background_blurring", action='store_false', dest="blur_background")
    parser.add_argument("--data_res", dest="data_res")
    parser.add_argument("--thickness", dest="thickness")
    parser.add_argument("--downsample", dest="downsample")
    parser.add_argument("--blur_range", dest="blur_range")
    parser.add_argument("--crop_channel_2", type=str, dest="crop_channel_2")
    parser.add_argument("--bias_shape_factor", type=float, dest="bias_shape_factor")
    parser.add_argument("--bias_std", type=float, dest="bias_field_std_dev")

    # Architecture parameters
    parser.add_argument("--n_levels", type=int, dest="n_levels")
    parser.add_argument("--conv_per_level", type=int, dest="nb_conv_per_level")
    parser.add_argument("--conv_size", type=int, dest="conv_size")
    parser.add_argument("--unet_feat", type=int, dest="unet_feat_count")
    parser.add_argument("--feat_mult", type=int, dest="feat_multiplier")
    parser.add_argument("--dropout", type=float, dest="dropout")
    parser.add_argument("--no_batch_norm", action='store_true', dest="no_batch_norm")

    # Training parameters
    parser.add_argument("--lr", type=float, dest="lr")
    parser.add_argument("--lr_decay", type=float, dest="lr_decay")
    parser.add_argument("--wl2_epochs", type=int, dest="wl2_epochs")
    parser.add_argument("--dice_epochs", type=int, dest="dice_epochs")
    parser.add_argument("--steps_per_epoch", type=int, dest="steps_per_epoch")
    parser.add_argument("--background_weight", type=float, dest="background_weight")
    parser.add_argument("--include_background", action='store_true', dest="include_background")
    parser.add_argument("--loss_cropping", type=int, dest="loss_cropping")

    # Resuming parameters
    parser.add_argument("--load_model_file", type=str, dest="load_model_file")
    parser.add_argument("--initial_epoch_wl2", type=int, dest="initial_epoch_wl2")
    parser.add_argument("--initial_epoch_dice", type=int, dest="initial_epoch_dice")

    # Saving paths
    parser.add_argument("--save_generation_labels", type=str, dest="save_generation_labels")

    args = parser.parse_args()
    logging.getLogger('tensorflow').disabled = True
    training(**vars(args))
